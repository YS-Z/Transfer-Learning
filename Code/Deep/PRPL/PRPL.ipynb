{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  \n",
    "from torchvision import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import mmd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.io import loadmat, savemat\n",
    "from datetime import datetime\n",
    "# dir(models)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # if not use cpu\n",
    "print(device)\n",
    "\n",
    "\n",
    "    \n",
    "class create_model(nn.Module):\n",
    "    def __init__(self,feature_Size,num_classes,transfer_loss='mmd'):\n",
    "        super(create_model, self).__init__()\n",
    "        self.device = device\n",
    "        self.transfer_loss = transfer_loss\n",
    "        Shared_layer_list = [nn.Linear(feature_Size, 512), \n",
    "                             nn.ReLU(),\n",
    "                             nn.BatchNorm1d(512),\n",
    "                             nn.Linear(512, 512),\n",
    "                             nn.ReLU(),\n",
    "                             nn.BatchNorm1d(512),\n",
    "                             nn.Dropout(p=0.1),\n",
    "                             nn.Linear(512, num_classes)]\n",
    "        \n",
    "        self.Shared_layer = nn.Sequential(*Shared_layer_list) \n",
    "        \n",
    "        \n",
    "    def forward(self, source, target):\n",
    "               \n",
    "        source_clf = self.Shared_layer(source)\n",
    "        target_clf = self.Shared_layer(target)\n",
    "        transfer_loss =  self.adapt_loss(source_clf, target_clf, self.transfer_loss)\n",
    "\n",
    "        return source_clf, transfer_loss\n",
    "    \n",
    "        \n",
    "    \n",
    "    def predict(self, x):\n",
    "\n",
    "        clf = self.Shared_layer(x)\n",
    "        return clf\n",
    "\n",
    "    def adapt_loss(self, X, Y, adapt_loss):\n",
    "\n",
    "        if adapt_loss == 'mmd':\n",
    "            mmd_loss = mmd.MMD_loss()\n",
    "            loss = mmd_loss(X, Y) \n",
    "        else:\n",
    "            loss = 0\n",
    "        return loss     \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "def batch_generator(data, batch_size):\n",
    "    \"\"\"Generate batches of data.\n",
    "\n",
    "    Given a list of numpy data, it iterates over the list and returns batches of the same size\n",
    "    This\n",
    "    \"\"\"\n",
    "    all_examples_indices = len(data[0])\n",
    "    while True:\n",
    "        mini_batch_indices = np.random.choice(all_examples_indices, size=batch_size, replace=False)\n",
    "        tbr = [k[mini_batch_indices] for k in data]\n",
    "        yield tbr    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain adaptation on Office31 dataset\n",
      "amazon to webcam\n",
      "92.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zys61\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.35\n",
      "95.6\n",
      "95.85\n",
      "0:00:09.986435\n",
      "amazon to dslr\n",
      "95.98\n",
      "96.99\n",
      "96.79\n",
      "96.99\n",
      "0:00:18.119342\n",
      "webcam to amazon\n",
      "80.37\n",
      "81.82\n",
      "82.22\n",
      "82.43\n",
      "0:00:26.337195\n",
      "webcam to dslr\n",
      "98.59\n",
      "99.2\n",
      "99.2\n",
      "99.2\n",
      "0:00:34.150993\n",
      "dslr to amazon\n",
      "80.05\n",
      "82.14\n",
      "82.82\n",
      "82.96\n",
      "0:00:42.270286\n",
      "dslr to webcam\n",
      "96.1\n",
      "96.98\n",
      "97.11\n",
      "97.11\n",
      "0:00:50.159086\n",
      "Average accuracy original: 90.53\n",
      "Average accuracy 1 self learning: 92.08\n",
      "Average accuracy 2 self learning: 92.29\n",
      "Average accuracy 3 self learning: 92.42\n",
      "0:00:50.160083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zys61\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "start=datetime.now()\n",
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_seed(99) \n",
    "\n",
    "feature_Size=2560\n",
    "all_num_classes=[10,31,65]\n",
    "\n",
    "\n",
    "datasets=['Office_caltech_10','Office31','Office_home'];\n",
    "str_domains_Office_caltech_10 = ['caltech', 'amazon', 'webcam', 'dslr']; \n",
    "str_domains_Office31 = ['amazon', 'webcam', 'dslr']; \n",
    "str_domains_Office_home = ['Art', 'Clipart', 'Product', 'Real_World']; \n",
    "\n",
    "batch_size =64\n",
    "epochs = 9\n",
    "n_batch =30\n",
    "T = 3\n",
    "prob=[0.5,0.8,0.9]\n",
    "\n",
    "\n",
    "    \n",
    "Acc1={}\n",
    "for k in range(len(datasets)-2):\n",
    "    k+=1\n",
    "    print('Domain adaptation on '+ datasets[k] +' dataset')\n",
    "    task=1\n",
    "    for ii in range(len(eval('str_domains_'+datasets[k]))):\n",
    "        x=loadmat('./' +datasets[k] + '/' +eval('str_domains_'+datasets[k])[ii]+'_efficientnet.mat')  #source features\n",
    "        Xs = torch.from_numpy(x['features']).to(device)\n",
    "        Ys = torch.from_numpy(np.squeeze(x['labels'], axis=1)).long().to(device)\n",
    "        S_batches = batch_generator([Xs, Ys], batch_size)\n",
    "        for jj in range(len(eval('str_domains_'+datasets[k]))):\n",
    "            if ii ==jj:\n",
    "                 continue\n",
    "            print(eval('str_domains_'+datasets[k])[ii] + ' to ' + eval('str_domains_'+datasets[k])[jj])\n",
    "\n",
    "            xx=loadmat('./' +datasets[k] + '/' +eval('str_domains_'+datasets[k])[jj]+'_efficientnet.mat') #target features\n",
    "\n",
    "            Xt = torch.from_numpy(xx['features']).to(device)\n",
    "            Yt = torch.from_numpy(np.squeeze(xx['labels'], axis=1)).long().to(device)\n",
    "            T_batches = batch_generator([Xt,Yt], batch_size)\n",
    "\n",
    "            model=create_model(Xs.shape[1],all_num_classes[k],transfer_loss='mmd')\n",
    "            model =model.to(device)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss().to(device)\n",
    "            optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "            Yt_p = None                \n",
    "            for t in range(T+1):# Recurrent Pseudo-Labeling\n",
    "                if Yt_p is not None:\n",
    "                    Xs = torch.from_numpy(x['features']).to(device)\n",
    "                    Ys = torch.from_numpy(np.squeeze(x['labels'], axis=1)).long().to(device) # To prevent bad labels\n",
    "                    sm = torch.nn.Softmax()\n",
    "                    probabilities = sm(Yt_p) \n",
    "                    Xs=torch.cat([Xs,Xt[probabilities.max(axis=1).values>prob[t-1],:]], 0)\n",
    "                    Ys=torch.cat([Ys,pred[probabilities.max(axis=1).values>prob[t-1]]], 0)         \n",
    "                    S_batches = batch_generator([Xs, Ys], batch_size)\n",
    "\n",
    "                for epoch in range(epochs): \n",
    "                    for i in range(n_batch):\n",
    "\n",
    "                        X0, Y0 = next(S_batches)\n",
    "                        X1, Y1 = next(T_batches)   \n",
    "                        running_loss = 0.0\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs, transfer_loss= model(X0,X1)\n",
    "                        clf_loss = criterion(outputs, Y0)   \n",
    "                        loss = clf_loss + transfer_loss \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                Yt_p = model.predict(Xt)\n",
    "                pred = torch.max(Yt_p, 1)[1]\n",
    "                Acc = 100 * (pred == Yt).sum().item() / Yt.size(0)\n",
    "                print(round(Acc,2))   \n",
    "                Acc1[t,task]=round(Acc,2)\n",
    "            print(datetime.now()-start)\n",
    "            Acc1[t,task]=round(Acc,2)\n",
    "            task+=1       \n",
    "            \n",
    "all_mean=np.mean(np.array(list(Acc1.items()))[:,1].reshape((int(np.array(list(Acc1.items())).shape[0]/(T+1)), T+1)),0)\n",
    "for t in range(T+1):\n",
    "    if t==0:\n",
    "        print('Average accuracy original:', round(all_mean[t],2)) \n",
    "    else:\n",
    "        print('Average accuracy '+ str(t) +' self learning:', round(all_mean[t],2))\n",
    "print(datetime.now()-start)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
